# import lib
import os
import time
import re
import openai
import streamlit as st
from dotenv import load_dotenv
from pinecone import Pinecone
from langchain_pinecone import PineconeVectorStore
from langchain_community.embeddings.openai import OpenAIEmbeddings
from openai import AsyncOpenAI
import asyncio
from streamlit_star_rating import st_star_rating
import yaml
import pandas as pd
import matplotlib.pyplot as plt
from retriever import process_query  # Import query expansion module

load_dotenv()

PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')
pc = Pinecone(api_key=PINECONE_API_KEY)

index_name = 'llm-chatbot-gpt'
embedding = None
client = None
pVS = None


primer2 = f"""B√¢y gi·ªù b·∫°n h√£y ƒë√≥ng vai tr√≤ l√† m·ªôt lu·∫≠t s∆∞ xu·∫•t s·∫Øc v·ªÅ lu·∫≠t h√¥n nh√¢n v√† gia ƒë√¨nh ·ªü Vi·ªát Nam.
T√¥i s·∫Ω h·ªèi b·∫°n c√°c c√¢u h·ªèi v·ªÅ t√¨nh hu·ªëng th·ª±c t·∫ø li√™n quan t·ªõi lu·∫≠t h√¥n nh√¢n v√† gia ƒë√¨nh. B·∫°n h√£y t√≥m t·∫Øt t√¨nh hu·ªëng
v√† ƒë∆∞a ra c√°c c√¢u h·ªèi ng·∫Øn g·ªçn g·ªìm t·ª´ kho√° li√™n quan t·ªõi ph√°p lu·∫≠t ƒë∆∞·ª£c suy lu·∫≠n t·ª´ ph·∫ßn th√¥ng tin c√≥ trong t√¨nh hu·ªëng. C√°c c√¢u tr·∫£ l·ªùi c·ªßa b·∫°n
ƒë·ªÅu l√† ti·∫øng vi·ªát.

Sau ƒë√¢y l√† m·ªôt s·ªë v√≠ d·ª• v√† ph·∫ßn t√≥m t·∫Øt:
1. T√¨nh hu·ªëng: Bi·∫øt m√¨nh ƒë·ªß tu·ªïi k·∫øt h√¥n v√† ƒë√°p ·ª©ng c√°c ƒëi·ªÅu ki·ªán k·∫øt h√¥n, Anh S v√† ch·ªã Y d·ª± ƒë·ªãnh ƒëi ƒëƒÉng k√Ω k·∫øt h√¥n tr∆∞·ªõc khi t·ªï ch·ª©c l·ªÖ c∆∞·ªõi 02 th√°ng. Ch·ªã Y v√† anh S c√≥ h·ªô kh·∫©u th∆∞·ªùng tr√∫ ·ªü hai t·ªânh kh√°c nhau, anh ch·ªã mu·ªën bi·∫øt vi·ªác ƒëƒÉng k√Ω k·∫øt h√¥n th·ª±c hi·ªán t·∫°i c∆° quan n√†o v√† c·∫ßn th·ª±c hi·ªán th·ªß t·ª•c g√¨?
-> T√≥m t·∫Øt: Th·ªß t·ª•c ƒëƒÉng k√Ω k·∫øt h√¥n l√† g√¨, h·ªô kh·∫©u th∆∞·ªùng tr√∫ trong th·ªß t·ª•c k·∫øt h√¥n

2. √îng b√† B c√≥ con trai ƒë√£ 25 tu·ªïi, b·ªã b·ªánh ƒëao b·∫©m sinh. V√¨ mu·ªën l·∫•y v·ª£ cho con trai, b√† B ƒë√£ t√¨m c√°ch vu c√°o cho ch·ªã Y ‚Äì ng∆∞·ªùi gi√∫p vi·ªác l·∫•y tr·ªôm s·ªë ti·ªÅn 1.000.000 ƒë·ªìng. B√† B  ƒëe d·ªça n·∫øu ch·ªã Y kh√¥ng mu·ªën b·ªã b√°o c√¥ng an, kh√¥ng mu·ªën b·ªã ƒëi t√π th√¨ ph·∫£i l·∫•y con trai b√†, v·ª´a ƒë∆∞·ª£c l√†m ch·ªß nh√†, kh√¥ng ph·∫£i l√†m ng∆∞·ªùi gi√∫p vi·ªác l·∫°i c√≥ cu·ªôc s·ªëng sung t√∫c. V√¨ nh·∫≠n th·ª©c h·∫°n ch·∫ø, tr√¨nh ƒë·ªô vƒÉn h√≥a th·∫•p n√™n ch·ªã Y ƒë√£ ƒë·ªìng √Ω l·∫•y con trai b√† B. H√¥n l·ªÖ ch·ªâ t·ªï ch·ª©c gi·ªØa hai gia ƒë√¨nh m√† kh√¥ng l√†m th·ªß t·ª•c ƒëƒÉng k√Ω k·∫øt h√¥n t·∫°i ph∆∞·ªùng. Vi·ªác l√†m c·ªßa b√† B c√≥ vi ph·∫°m ph√°p lu·∫≠t kh√¥ng? N·∫øu c√≥ th√¨ b·ªã x·ª≠ ph·∫°t nh∆∞ th·∫ø n√†o?
-> T√≥m t·∫Øt: c∆∞·ª°ng √©p k·∫øt h√¥n c√≥ b·ªã x·ª≠ ph·∫°t kh√¥ng, c∆∞·ª°ng √©p k·∫øt h√¥n b·ªã x·ª≠ ph·∫°t nh∆∞ th·∫ø n√†o 

3. T√¥i ƒë√£ k·∫øt h√¥n ƒë∆∞·ª£c 6 th√°ng, nh∆∞ng ch∆∞a chuy·ªÉn h·ªô kh·∫©u v·ªÅ nh√† ch·ªìng (·ªü x√£ X, huy·ªán B, t·ªânh A), h·ªô kh·∫©u c·ªßa t√¥i v·∫´n ƒëang ·ªü nh√† b·ªë m·∫π ƒë·∫ª (x√£ Y, huy·ªán C, t·ªânh D). Nay t√¥i c√≥ nguy·ªán v·ªçng chuy·ªÉn h·ªô kh·∫©u v·ªÅ nh√† ch·ªìng th√¨ c√≥ ƒë∆∞·ª£c kh√¥ng v√† th·ªß t·ª•c th·ª±c hi·ªán nh∆∞ th·∫ø n√†o? Ai c√≥ th·∫©m quy·ªÅn gi·∫£i quy·∫øt?
-> t√≥m t·∫Øt: c√≥ ƒë∆∞·ª£c chuy·ªÉn h·ªô kh·∫©u v·ªÅ nh√† ch·ªìng kh√¥ng, Th·ªß t·ª•c chuy·ªÉn h·ªô kh·∫©u, Ai gi·∫£i quy·∫øt th·ªß t·ª•c chuy·ªÉn h·ªô kh·∫©u
"""

primer1 = f"""B√¢y gi·ªù b·∫°n h√£y ƒë√≥ng vai tr√≤ l√† m·ªôt lu·∫≠t s∆∞ xu·∫•t s·∫Øc v·ªÅ lu·∫≠t h√¥n nh√¢n v√† gia ƒë√¨nh ·ªü Vi·ªát Nam.
T√¥i s·∫Ω h·ªèi b·∫°n c√°c c√¢u h·ªèi v·ªÅ t√¨nh hu·ªëng th·ª±c t·∫ø li√™n quan t·ªõi lu·∫≠t h√¥n nh√¢n v√† gia ƒë√¨nh. B·∫°n s·∫Ω tr·∫£ l·ªùi c√¢u h·ªèi
d·ª±a tr√™n th√¥ng tin t√¥i cung c·∫•p v√† th√¥ng tin c√≥ trong c√¢u h·ªèi. N·∫øu th√¥ng tin t√¥i cung c·∫•p kh√¥ng ƒë·ªß ƒë·ªÉ tr·∫£ l·ªùi
h√£y n√≥i r·∫±ng 'T√¥i kh√¥ng bi·∫øt'. C√°c c√¢u tr·∫£ l·ªùi c·ªßa b·∫°n ƒë·ªÅu l√† ti·∫øng vi·ªát. 
L∆∞u √Ω: N√™u r√µ ƒëi·ªÅu lu·∫≠t s·ªë m·∫•y ƒë·ªÉ tr·∫£ l·ªùi t√¨nh hu·ªëng.
"""



def check_string(s):
    pattern = r"N·∫øu b·∫°n c·∫ßn"
    return re.search(pattern, s) is not None


def remove_string(s):
    pattern = r"N·∫øu b·∫°n c·∫ßn .*"
    return re.sub(pattern, "", s)


async def qa1(prompt):
    """
    Get the primary answer from GPT without additional context retrieval.
    """
    response = await client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": primer1},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content.strip()


async def qa2(prompt):
    """
    Expand query, retrieve documents, and generate an enhanced response.
    Include expanded terms and retrieved contexts for transparency.
    """
    # Expand query and retrieve documents
    query_data = process_query(prompt, k=3)
    expanded_terms = query_data["expanded_terms"]  # List of expanded terms
    documents = query_data["documents"]           # List of retrieved documents

    # Combine retrieved content
    context = "\n".join(doc.page_content for doc in documents) + "\n" + prompt

    # Get the enhanced answer from GPT
    response = await client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": primer1},
            {"role": "user", "content": context}
        ]
    )
    answer = response.choices[0].message.content.strip()

    if check_string(answer):
        answer = remove_string(answer)

    return answer, documents, expanded_terms  # Return the answer, contexts, and expanded terms


async def page_1():
    global client
    client = AsyncOpenAI(api_key=st.session_state.openai_apikey)

    st.title("üßë‚Äçüíªüí¨ A RAG chatbot for family and marriage legal questions")
    """
    ƒê√¢y l√† chatbot gi√∫p ng∆∞·ªùi d√¢n t√¨m hi·ªÉu lu·∫≠t h√¥n nh√¢n v√† gia ƒë√¨nh. B·∫°n h√£y h·ªèi nh·ªØng c√¢u h·ªèi c√≥ li√™n quan t·ªõi lu·∫≠t n√†y nh√©.
    """

    # Display chat history
    for conversation in st.session_state.chat_history:
        st.chat_message("user").write(conversation['question'])
        col1, col2 = st.columns(2)
        with col1:
            st.chat_message("assisstant").write(conversation['answer1'])
        with col2:
            st.chat_message("assisstant").write(conversation['answer2'])

        # Box to display expanded terms
        with st.expander("Expanded Terms"):
            st.write(", ".join(conversation['expanded_terms']))

        # Box to display retrieved contexts
        with st.expander("Retrieved Contexts"):
            for i, doc in enumerate(conversation['retrieved_contexts']):
                st.write(f"**Context {i + 1}:** {doc.page_content}")

        st.write(f"You rated this answer {conversation['stars']} :star:")

    if "stars" not in st.session_state:
        st.session_state.stars = ""

    if st.session_state.stars:
        # Store feedback
        st.session_state.chat_history.append(
            {
                'question': st.session_state['question'],
                'answer1': st.session_state['msg1'],
                'answer2': st.session_state['msg2'],
                'expanded_terms': st.session_state['expanded_terms'],
                'retrieved_contexts': st.session_state['retrieved_contexts'],
                'stars': st.session_state['stars']
            }
        )
        df = pd.read_csv('result.csv')
        new_row = {
            'question': st.session_state['question'],
            'gpt_answer': st.session_state['msg1'],
            'enhanced_answer': st.session_state['msg2'],
            'rating': st.session_state['stars']
        }
        df = df._append(new_row, ignore_index=True)
        df.to_csv('./result.csv', index=False)

        st.chat_message("user").write(st.session_state['question'])
        col1, col2 = st.columns(2)
        with col1:
            st.chat_message("assisstant").write(st.session_state['msg1'])
        with col2:
            st.chat_message("assisstant").write(st.session_state['msg2'])

        with st.expander("Expanded Terms"):
            st.write(", ".join(st.session_state['expanded_terms']))

        with st.expander("Retrieved Contexts"):
            for i, doc in enumerate(st.session_state['retrieved_contexts']):
                st.write(f"**Context {i + 1}:** {doc.page_content}")

        st.write(f"You rated this answer {st.session_state['stars']} :star:")
        del st.session_state.prompt

    if prompt := st.chat_input():
        st.session_state.prompt = prompt
        st.chat_message("user").write(prompt)
        msg1 = await qa1(prompt)
        msg2, retrieved_contexts, expanded_terms = await qa2(prompt)

        col1, col2 = st.columns(2)
        with col1:
            st.chat_message("assisstant").write(msg1)
        with col2:
            st.chat_message("assisstant").write(msg2)

        # Save retrieved contexts and expanded terms
        st.session_state['retrieved_contexts'] = retrieved_contexts
        st.session_state['expanded_terms'] = expanded_terms

        # Box to display expanded terms
        with st.expander("Expanded Terms"):
            st.write(", ".join(expanded_terms))

        # Box to display retrieved contexts
        with st.expander("Retrieved Contexts"):
            for i, doc in enumerate(retrieved_contexts):
                st.write(f"**Context {i + 1}:** {doc.page_content}")

        st.session_state.question = prompt
        st.session_state.msg1 = msg1
        st.session_state.msg2 = msg2

    if "prompt" in st.session_state:
        stars = st_star_rating("Please rate your experience", maxValue=4, defaultValue=3, key="stars")


async def page_2():
    # T·∫°o m·∫´u DataFrame v·ªõi 4 c·ªôt
    df = pd.read_csv('result.csv')

    # Hi·ªÉn th·ªã DataFrame trong Streamlit
    st.write("Data:")
    st.write(df)
    st.write(f"There is total of {len(df)} answered questons")
    # Visualize c·ªôt "score" b·∫±ng Matplotlib trong Streamlit
    st.write("Histogram of 'rating' column:")
    fig, ax = plt.subplots()
    ax.hist(df['rating'], bins=4)
    ax.set_xlabel('Rating')
    ax.set_ylabel('Count')

    # Ch·ªâ hi·ªÉn th·ªã c√°c gi√° tr·ªã 1, 2, 3, 4 tr√™n tr·ª•c x
    ax.set_xticks([1, 2, 3, 4])
    ax.set_xticklabels(['1', '2', '3', '4'])

    # Hi·ªÉn th·ªã gi√° tr·ªã c·ªßa t·ª´ng c·ªôt trong histogram
    for i, count in enumerate(ax.patches):
        ax.annotate(str(int(count.get_height())),
                    xy=(count.get_x() + count.get_width() / 2, count.get_height()),
                    ha='center', va='bottom')

    st.pyplot(fig)


def page_3():
    # Giao di·ªán nh·∫≠p API key
    st.title("Nh·∫≠p API Key")
    api_key_input = st.text_input("API Key:", type="password")
    st.session_state.openai_apikey = api_key_input
    # N√∫t ƒë·ªÉ l∆∞u API key
    if st.button("L∆∞u API Key"):
        st.success("API Key ƒë√£ ƒë∆∞·ª£c l∆∞u!")


PAGES = {
    "Chat": page_1,
    "Statistic": page_2,
    "Update API KEY": page_3
}

def main():
    st.set_page_config(page_title="RAG Chatbot")
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    if "openai_apikey" not in st.session_state:
        st.session_state.openai_apikey = os.getenv('OPENAI_API_KEY')
    # asyncio.run(question_answering())

    st.sidebar.title("Navigation")
    choice = st.sidebar.selectbox("Select an option", list(PAGES.keys()))
    # Call the page function
    if choice != "Update API KEY":
        asyncio.run(PAGES[choice]())
    else:
        PAGES[choice]()

if __name__ == "__main__":
    main()


